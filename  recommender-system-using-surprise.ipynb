{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5de1f485",
   "metadata": {},
   "source": [
    "### Build a Simple Recommender System Using Surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5622fa2",
   "metadata": {},
   "source": [
    "This is a Jupyter Notebook. When you execute code within the notebook, the results appear beneath the code. To execute a code chunk, place your cursor on the cell and press Shift+Enter.\n",
    "\n",
    "Recommender Systems are used to predict user preferences or we can say that these are systems that help people find things when the manual process of selection is a little bit challenging because of too many choices or alternatives. The best examples are Amazon recommending us the next book to read or Netflix suggesting the next movie to watch.\n",
    "There are three types of recommender systems.\n",
    "<ul>\n",
    "    <li>Collaborative filtering</li>\n",
    "    <li>Content-based filtering</li>\n",
    "    <li>Hybrid recommender system</li>\n",
    "</ul>\n",
    "We are going to build a recommender system using the collaborative filtering technique. \n",
    "Collaborative filtering is the technique of making predictions (filtering) about the interests of a user by collecting preferences or taste information from many users (collaborating).\n",
    "\n",
    "[Surprise](https://github.com/NicolasHug/Surprise) is a Python [scikit](https://www.scipy.org/scikits.html) for building and testing recommender systems that deal with explicit rating data. \n",
    "We will make use of this library for building the collaborative filtering based recommender system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe897c1",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac9e7fe",
   "metadata": {},
   "source": [
    "You can install Surprise on your machine using pip cor conda. You'll also need numpy and a C compiler. The recommended method for windows users is using conda):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b29516",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install scikit-surprise\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bb14d9",
   "metadata": {},
   "source": [
    "With conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b40c418",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -c conda-forge scikit-surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00243acb",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc884fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from surprise import Reader, Dataset\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import SVD, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02600d6",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90a09fb",
   "metadata": {},
   "source": [
    "We are going to use the Amazon's clothing, shoes and jewellery rating dataset from [here](https://jmcauley.ucsd.edu/data/amazon/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e24f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames=['reviewerID', 'asin', 'overall', 'unixReviewTime'] \n",
    "data = pd.read_csv('./data/ratings.csv', names=colnames, header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc383389",
   "metadata": {},
   "source": [
    "As you can see the data is loaded using pandas. We have four columns reviewerID, asin, overall and unixReviewTime.<br/>\n",
    "\n",
    "where\n",
    "<ul>\n",
    "    <li>reviewerID - ID of the reviewer, e.g. A2SUAM1J3GNN3B</li>\n",
    "    <li>asin - ID of the product, e.g. 0000013714</li>\n",
    "    <li>overall - rating of the product</li>\n",
    "    <li>unixReviewTime - time of the review (unix time)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cc1707",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f8bcdc",
   "metadata": {},
   "source": [
    "The dataset contains 5748920 rows of data. Now we will check the value counts of the column overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abcabef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.overall.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fae16c7",
   "metadata": {},
   "source": [
    "We can see that the rating of 5.0 has the highest value counts. This means more people rated an item 5.0. It is shown in the plot below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26be5461",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.overall.value_counts().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b21a1ba",
   "metadata": {},
   "source": [
    "Now we will check for null values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a6713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba85d11",
   "metadata": {},
   "source": [
    "As there are no null values in the dataset we will jump into the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfece424",
   "metadata": {},
   "source": [
    "### Load Data into Surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3c0315",
   "metadata": {},
   "source": [
    "We don't need the timestamp column for this. So we will remove that column from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14355e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['reviewerID', 'asin', 'overall', 'unixReviewTime']]\n",
    "input_data = data.iloc[:, :-1]\n",
    "input_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf40fa79",
   "metadata": {},
   "source": [
    "To load the dataset from pandas data frame to Surprise, we will use the load_from_df() method. We will also need a Reader object with the rating_scale the parameter specified as (1,5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd1148a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1,5))\n",
    "input_data = Dataset.load_from_df(input_data[['reviewerID', 'asin', 'overall']], reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc17a58d",
   "metadata": {},
   "source": [
    "Now we will split the input_data to train and test data in an 80:20 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4743ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(input_data, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72feef02",
   "metadata": {},
   "source": [
    "The most known and widely used matrix decomposition method is the Singular-Value Decomposition or SVD. All matrices have an SVD, which makes SVD more stable than other methods. So we will use this technique for training our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bebb02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = SVD()\n",
    "predictions = algo.fit(train_data).test(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea473e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy.rmse(predictions)\n",
    "accuracy.mae(predictions)\n",
    "accuracy.mse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac84d87",
   "metadata": {},
   "source": [
    "To inspect our predictions in details, we are going to build a pandas data frame with all the predictions. The following code is largely taken from this [notebook](https://nbviewer.jupyter.org/github/NicolasHug/Surprise/blob/master/examples/notebooks/KNNBasic_analysis.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee87bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Iu(uid):\n",
    "    \"\"\" return the number of items rated by given user\n",
    "    args: \n",
    "      uid: the id of the user\n",
    "    returns: \n",
    "      the number of items rated by the user\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return len(train_data.ur[train_data.to_inner_uid(uid)])\n",
    "    except ValueError: # user was not part of the trainset\n",
    "        return 0\n",
    "    \n",
    "def get_Ui(iid):\n",
    "    \"\"\" return number of users that have rated given item\n",
    "    args:\n",
    "      iid: the raw id of the item\n",
    "    returns:\n",
    "      the number of users that have rated the item.\n",
    "    \"\"\"\n",
    "    try: \n",
    "        return len(train_data.ir[train_data.to_inner_iid(iid)])\n",
    "    except ValueError:\n",
    "        return 0\n",
    "    \n",
    "df = pd.DataFrame(predictions, columns=['uid', 'iid', 'rui', 'est', 'details'])\n",
    "df['Iu'] = df.uid.apply(get_Iu)\n",
    "df['Ui'] = df.iid.apply(get_Ui)\n",
    "df['err'] = abs(df.est - df.rui)\n",
    "best_predictions = df.sort_values(by='err')[:1000]\n",
    "worst_predictions = df.sort_values(by='err')[-1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012171ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289ae312",
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8c49ec",
   "metadata": {},
   "source": [
    "That's it! We build a fashion apparel recommender system using the Surprise library. You can perform hyperparameters tuning and Cross-validation with Surprise to get more accurate predictions. You can find the official Surprise documentation [here](https://surprise.readthedocs.io/en/stable/index.html).\n",
    "I love your feedback, please let me know what you think."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5643cd33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
